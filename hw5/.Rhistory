x1_test = x1[((nrow(x1)/2)+1):nrow(x1),]
y1_test = y1[((nrow(x1)/2)+1):nrow(x2),]
w1 = solve(t(x1_train)%*%x1_train)%*%t(x1_train)%*%y1_train
w1
x2_train = x2[1:(nrow(x2)/2),]
y2_train = y2[1:(nrow(x2)/2),]
x2_test = x2[((nrow(x2)/2)+1):nrow(x2),]
y2_test = y2[((nrow(x2)/2)+1):nrow(x2),]
w2 = solve(t(x2_train)%*%x2_train)%*%t(x2_train)%*%y2_train
w2
yhat1_test = x1_test%*%w1
error1 = (y1_test-yhat1_test)^2
SSE1 = sum(error1)
SSE1
yhat2_test = x2_test%*%w2
error2 = (y2_test-yhat2_test)^2
SSE2 = sum(error2)
SSE2
x = as.matrix(read.table("D:/Data Mining/hw5/pred1.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp1.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
# obtaining first best predictor variable
sse = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
X = x_train[,c(i)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse[i] = sum(error)
}
v1 = which.min(sse)
sse[v1]
# obtaining the second best predictor variable
sse1 = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
if (i == v1) {
sse1[i] = Inf
}
else {
X = x_train[,c(i,v1)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse1[i] = sum(error)
}
}
v2 = which.min(sse1)
sse1[v2]
# obtaining the third best predictor variable
sse2 = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
if (i == v1 | i == v2) {
sse2[i] = Inf
}
else {
X = x_train[,c(i,v1,v2)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse2[i] = sum(error)
}
}
v3 = which.min(sse2)
sse2[v3]
v1
v2
v3
x_train_new = x_train[,c(16,21,47)]
x_test_new = x_test[,c(16,21,47)]
w_new = solve(t(x_train_new)%*%x_train_new)%*%t(x_train_new)%*%y_train
yhat_test_new = x_test_new%*%w_new
error_new = (y_test-yhat_test_new)^2
sse_new = sum(error_new)
sse_new
w = solve(t(x_train)%*%x_train)%*%t(x_train)%*%y_train
yhat_test = x_test%*%w
error = (y_test-yhat_test)^2
sse = sum(error)
sse
x = as.matrix(read.table("D:/Data Mining/hw5/pred1.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp1.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
# obtaining first best predictor variable
sse = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
X = x_train[,c(i)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse[i] = sum(error)
}
v1 = which.min(sse)
sse[v1]
# obtaining the second best predictor variable
sse1 = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
if (i == v1) {
sse1[i] = Inf
}
else {
X = x_train[,c(i,v1)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse1[i] = sum(error)
}
}
v2 = which.min(sse1)
sse1[v2]
# obtaining the third best predictor variable
sse2 = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
if (i == v1 | i == v2) {
sse2[i] = Inf
}
else {
X = x_train[,c(i,v1,v2)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse2[i] = sum(error)
}
}
v3 = which.min(sse2)
sse2[v3]
v1
v2
v3
x_train_new = x_train[,c(16,21,47)]
x_test_new = x_test[,c(16,21,47)]
w_new = solve(t(x_train_new)%*%x_train_new)%*%t(x_train_new)%*%y_train
yhat_test_new = x_test_new%*%w_new
error_new = (y_test-yhat_test_new)^2
sse_new = sum(error_new)
sse_new
# with all predictors
w = solve(t(x_train)%*%x_train)%*%t(x_train)%*%y_train
yhat_test = x_test%*%w
error = (y_test-yhat_test)^2
sse = sum(error)
sse
x_train_new = x_train[,c(16,21,47)]
x_test_new = x_test[,c(16,21,47)]
w_new = solve(t(x_train_new)%*%x_train_new)%*%t(x_train_new)%*%y_train
yhat_test_new = x_test_new%*%w_new
error_new = (y_test-yhat_test_new)^2
sse_new = sum(error_new)
sse_new
x_train_new = x_train[,c(16,21,47)]
x_test_new = x_test[,c(16,21,47)]
w_new = solve(t(x_train_new)%*%x_train_new)%*%t(x_train_new)%*%y_train
yhat_test_new = x_test_new%*%w_new
error_new = (y_test-yhat_test_new)^2
sse_new = sum(error_new)
sse_new
w = solve(t(x_train)%*%x_train)%*%t(x_train)%*%y_train
yhat_test = x_test%*%w
error = (y_test-yhat_test)^2
sse = sum(error)
sse
ts = as.matrix(read.table("D:/Data Mining/hw5/time_series.dat"))
y = ts[3:nrow(ts),]
x1 = ts[1:(nrow(ts)-2),]
x2 = ts[2:(nrow(ts)-1),]
X = cbind(x1,x2)
w = solve(t(X)%*%X)%*%(t(X)%*%y)
yhat = X%*%w
error = y-yhat
alpha1 = w[1]
alpha2 = w[2]
variance = var(error)
alpha1
alpha2
variance
# Let lambda = 20
lambda = rep(20,ncol(x))
lambda = diag(lambda)
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
x = as.matrix(read.table("D:/Data Mining/hw5/pred2.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp2.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
# (a)
# Let lambda = 20
lambda = rep(20,ncol(x))
lambda = diag(lambda)
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
error = (y_test-yhat_test)^2
sse = sum(error)
sse
w = solve(t(x_train)%*%x_train)%*%t(x_train)%*%y_train
yhat_test1 = x_test%*%w
error1 = (yhat_test1-y_test)^2
sse1 = sum(error1)
sse1
x = as.matrix(read.table("D:/Data Mining/hw5/pred2.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp2.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
# (a)
# Let lambda = 20
lambda = rep(20,ncol(x))
lambda = diag(lambda)
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
# (b)
# Using ridge regrssion, computing SSE on test data
error = (y_test-yhat_test)^2
sse = sum(error)
sse
# computing SSE using plain regression
w = solve(t(x_train)%*%x_train)%*%t(x_train)%*%y_train
yhat_test1 = x_test%*%w
error1 = (yhat_test1-y_test)^2
sse1 = sum(error1)
sse1
lambda = seq(0,20,by=0.5)
sse = rep(0,length(lambda))
for (i in 1:length(lambda)){
lambda_matrix = diag(rep(lambda[i],ncol(x)))
what = solve(t(x_train)%*%x_train+lambda_matrix)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
error = (y_test-yhat_test)^2
sse[i] = sum(error)
}
value = data.frame(cbind(lambda,sse))
plot(value[2:nrow(value),],type="l")
value[which.min(value$sse),]
lambda_hat = diag(rep(7,ncol(x)))
w = solve(t(x_train)%*%x_train+lambda_hat)%*%t(x_train)%*%y_train
yhat = x_test%*%w
error = (y_test-yhat)^2
sse_min = sum(error)
sse_min
ts = as.matrix(read.table("D:/Data Mining/hw5/time_series.dat"))
y = ts[3:nrow(ts),]
x1 = ts[1:(nrow(ts)-2),]
x2 = ts[2:(nrow(ts)-1),]
X = cbind(x1,x2)
w = solve(t(X)%*%X)%*%(t(X)%*%y)
yhat = X%*%w
error = y-yhat
alpha1 = w[1]
alpha2 = w[2]
variance = var(error)
alpha1
alpha2
variance
x = as.matrix(read.table("D:/Data Mining/hw5/pred2.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp2.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
lambda = rep(20,ncol(x))
lambda = diag(lambda)
lambda = rep(20,ncol(x))
lambda = diag(lambda)
lambda
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
head(yhat_test)
lambda = seq(0,20,by=0.5)
sse = rep(0,length(lambda))
for (i in 1:length(lambda)){
lambda_matrix = diag(rep(lambda[i],ncol(x)))
what = solve(t(x_train)%*%x_train+lambda_matrix)%*%t(x_train)%*%y_train
lambda = seq(0,20,by=0.5)
sse = rep(0,length(lambda))
for (i in 1:length(lambda)){
lambda_matrix = diag(rep(lambda[i],ncol(x)))
what = solve(t(x_train)%*%x_train+lambda_matrix)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
error = (y_test-yhat_test)^2
sse[i] = sum(error)
}
}
x = as.matrix(read.table("D:/Data Mining/hw5/pred2.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp2.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
# (a)
# Let lambda = 20
lambda = rep(20,ncol(x))
lambda = diag(lambda)
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
# (b)
# Using ridge regrssion, computing SSE on test data
error = (y_test-yhat_test)^2
sse = sum(error)
sse
# computing SSE using plain regression
w = solve(t(x_train)%*%x_train)%*%t(x_train)%*%y_train
yhat_test1 = x_test%*%w
error1 = (yhat_test1-y_test)^2
sse1 = sum(error1)
sse1
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
what
yhat_test = x_test%*%what
head(yhat_test)
w = solve(t(X)%*%X)%*%(t(X)%*%Y)
df = read.csv("D:/Data Mining/hw5/Vocab.csv")
df1 = df[,c("education","vocabulary")]
# Creating feature vector X and class vector Y
X1 = df1[,1]
X2 = rep(1,length(X1))
X = cbind(X1,X2)
Y = df1[,2]
head(X)
## (b)
## Solving for w and reporting values of a and b
w = solve(t(X)%*%X)%*%(t(X)%*%Y)
a = w[1]
b = w[2]
a
b
yhat = X%*%w
df1$pred_vocab = yhat
head(df1)
plot(X1,Y, xlab = "education level", ylab="vocabulary score")
lines(X1,yhat)
df = read.csv("D:/Data Mining/hw5/ais.csv",stringsAsFactors=FALSE,sep=",")
X1 = df[,c(3,4,5,6,7,8,9,10,11,12)]
X2 = rep(1,nrow(X1))
X = cbind(X1,X2)
X = as.matrix(X)
head(df)
Y = df[,2]
X = as.matrix(X)
Y = df[,2]
w = solve(t(X)%*%X)%*%t(X)%*%Y
w
yhat = X%*%w
error = (Y-yhat)^2
sse = sum(error)
sse
ncol(X)
sse1 = rep(0,11)
for (i in 1:ncol(X)){
X1 = X[,-c(i)]
w1 = solve(t(X1)%*%X1)%*%t(X1)%*%Y
yhat1 = X1%*%w1
error1 = (Y-yhat1)^2
sse1[i] = sum(error1)
}
sse1
data(nottem)
y = nottem
n = length(y)
x = 1:n
# (a)
plot(x,y,type="b")
x1 = cos(2*pi*x/12)
x2 = sin(2*pi*x/12)
x3 = rep(1,n)
X = cbind(x1,x2,x3)
plot(x,y,type="b",col="green")
lines(x,yhat,type="b",col="red")
x1 = cos(2*pi*x/12)
x2 = sin(2*pi*x/12)
x3 = rep(1,n)
X = cbind(x1,x2,x3)
## Solving for w
w = solve(t(X)%*%X)%*%t(X)%*%y
w
## Predicting yhat from w
yhat = X%*%w
## plotting actual and predicted values of monthly beer sales
plot(x,y,type="b",col="green")
lines(x,yhat,type="b",col="red")
a = w[1]
b = w[2]
c = w[3]
X1 = cbind(x,x1,x2,x3)
## Solving for w using new feature vector
w1 = solve(t(X1)%*%X1)%*%t(X1)%*%y
w1
## Predicting yhat1 from new w
yhat1 = X1%*%w1
## Plotiing actual and
plot(x,y,type="b",col="green")
lines(x,yhat1,type="b",col="red")
x = as.matrix(read.table("D:/Data Mining/hw5/pred1.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp1.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
sse = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
X = x_train[,c(i)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse[i] = sum(error)
}
v1 = which.min(sse)
sse[v1]
sse1 = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
if (i == v1) {
sse1[i] = Inf
}
else {
X = x_train[,c(i,v1)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse1[i] = sum(error)
}
}
v2 = which.min(sse1)
sse1[v2]
sse2 = rep(0,ncol(x_train))
for (i in 1:ncol(x_train)){
if (i == v1 | i == v2) {
sse2[i] = Inf
}
else {
X = x_train[,c(i,v1,v2)]
w = solve(t(X)%*%X)%*%t(X)%*%y_train
yhat = X%*%w
error = (y_train-yhat)^2
sse2[i] = sum(error)
}
}
v3 = which.min(sse2)
sse2[v3]
v1
v2
v3
w = solve(t(x_train)%*%x_train)%*%t(x_train)%*%y_train
yhat_test = x_test%*%w
error = (y_test-yhat_test)^2
sse = sum(error)
sse
x = as.matrix(read.table("D:/Data Mining/hw5/pred2.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp2.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
lambda = rep(20,ncol(x))
lambda = diag(lambda)
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
yhat_test = x_test%*%what
error = (y_test-yhat_test)^2
sse = sum(error)
sse
ts = as.matrix(read.table("D:/Data Mining/hw5/time_series.dat"))
ts
head(ts)
x = as.matrix(read.table("D:/Data Mining/hw5/pred2.dat"))
y = as.matrix(read.table("D:/Data Mining/hw5/resp2.dat"))
x_train = x[1:(nrow(x)/2),]
y_train = y[1:(nrow(x)/2),]
x_test = x[((nrow(x)/2)+1):nrow(x),]
y_test = y[((nrow(x)/2)+1):nrow(x),]
# (a)
## Intialising lambda = 20
lambda = rep(20,ncol(x))
lambda = diag(lambda)
## SOlving for what using regularization and predicting on test dataset
what = solve(t(x_train)%*%x_train+lambda)%*%t(x_train)%*%y_train
what
## Reading timeseries data
ts = as.matrix(read.table("D:/Data Mining/hw5/time_series.dat"))
## Creating feature vector from ts as X(i-1) and X(i-2) and reponse vector y
y = ts[3:nrow(ts),]
x1 = ts[1:(nrow(ts)-2),]
x2 = ts[2:(nrow(ts)-1),]
X = cbind(x1,x2)
## Solve for w
w = solve(t(X)%*%X)%*%(t(X)%*%y)
# Compute error using y predicted
yhat = X%*%w
error = y-yhat
# Reporting values of alpha1 and alpha2 which is cooeficients of X(i-1) and
alpha1 = w[1]
alpha2 = w[2]
variance = var(error)
alpha1
alpha2
variance
## Solve for w
w = solve(t(X)%*%X)%*%(t(X)%*%y)
# Compute error using x(i) predicted and x(i) actual
yhat = X%*%w
error = y-yhat
# Reporting values of alpha1 and alpha2 which is cooeficients of X(i-1) and X(i-2) and variance of error which is e(i)
alpha1 = w[2]
alpha2 = w[1]
variance = var(error)
alpha1
alpha2
variance
